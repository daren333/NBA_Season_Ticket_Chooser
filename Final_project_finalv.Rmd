---
title: "Final_project_final_edition"
author: "Daren Ansher"
date: "5/21/2019"
output: html_document
---

A Little Context:
Sports tickets tend to be sold in three ways: single game tickets, multi-game plans, and season tickets. Since teams would rather sell more tickets at once, the best seating is generally reserved for those willing to purchase season tickets. Once a team has sold as many season tickets as they can, the leftover seats are sold in multi-game plans. Once no more people want to buy those, the remaining seats are sold as single game tickets. Because of this, single game tickets are either the seats nobody else wanted, which can be bought at face value via the team, or, they are good seats, bought on the secondary market for a sizable markup from a season ticketholder that can't go to a particular game. 

Due to this model, folks will often form a group to purchase and split season tickets - espically for sports with longer seasons. For instance, a four person group might split the cost of NBA season tickets, so that each person gets ten of the 41 home games in a season. This way, the best seats can be purchased at the best price, and nobody has to pay the entire cost of season tickets themselves. Also no one needs to attend 41 NBA games a year.

However, the one downside of this method is that you don't have the freedom to purchase tickets for only the games against oppenents that you want to see. Purchasing NBA season tickets requries purchasing tickets to every game and thus every opponent. Therefore groups need a way to divide tickets amongst themselves fairly so that each person gets some good games, and some bad ones.

Often, groups will remedy this by having a draft at the beginning of each season. Each person gets ten picks, and they take turns selecting which games they want. Each person considers the outcomes of prior seasons, this year's offseason acquisitions, and their anticipation of which teams will improve or regress, and combine them to make predictions about what opponents will be most worth spending a draft pick (and money) to go see. Since NBA team success is heavily dependent on a few of the best players, and since teams that keep their star players tend to be pretty consistent over 3-5 year spans, this is generally a pretty successful way to go about choosing tickets.

However, we think there might be a better way. While drafters often consider who the best teams will be, they rarely consider which teams will make for the most entertaining game. With the plethora of NBA data out there, we'd like to see if we can scrape some key statistics to predict which teams will make for the most entertaining game.


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(rvest)
library(tidyverse)
library(stringr)
```


First things first, we'll need to find statistcs for all of the NBA teams. ESPN.com has NBA team statistics for each of the past five years in a variety of useful categories. For each year, we can get general team stats, team's offensive and defensive ratings, and a few other useful stats categorized under misc. We'll identify the URLs for the tables that we want to use and then use the read_html function to scrape the pages for our data. We notice that for all three pages, statistics are held in the "mod-content" class located inside a div with ID "my-teams-table". We'll use the # CSS selector to select by ID and the . CSS selector to select by class. Finally, we notice that thet relevant statistics are all table row elements so we'll use tr to extract all table rows. More info on CSS Selectors can be viewed here: https://www.w3.org/TR/CSS2/selector.html.

```{r Pull ESPN Data}
off_url <- "http://www.espn.com/nba/statistics/team/_/stat/offense-per-game/year/2015/seasontype/2"

d_url <- "http://www.espn.com/nba/statistics/team/_/stat/defense-per-game/year/2015/seasontype/2"

misc_url <- "http://www.espn.com/nba/statistics/team/_/stat/miscellaneous-per-game/year/2015/seasontype/2"

  
  html_data <- read_html(off_url) %>% 
  html_node("#my-teams-table") %>% 
  html_nodes(".mod-content") %>% 
  html_nodes("tr") %>% 
  html_text()

  html_data



```



The HTML is a bit messy, so the pages will require a little cleanup. However it appears that each of the three pages are set up the same. Therefore, we should be able to scrape the statistics from the other two pages using the exact same commands. Further, we notice that the URL for the statistics pages of other years is exactly the same except for replacinig "2015" with whatever year we want the statistics for. Given how similar these tasks are, we can make things a little easier by writing a few functions!

We'll create two functions. The first will take a url, scrape the page for statistical information, and return the information we want. The second will take in a year, use the gsub function to replace the part of the URLs that say "20xx" with whatever year is provded, and then call the first function, inputting the modified URLs, to scrape that year's pages. The gsub function will use Regular Expressions to search for a given pattern and, wherever it finds that pattern, replace it with a different pattern. In this case, the pattern we are searching for is "20\\d{2}" aka the exact number "20" followed by exactly two additional digits ("\\d{2}"). Whenever that group of characters is found, it will replace those characters with the input year. For more information about Regular Expressions and text manipulation, see here: https://r4ds.had.co.nz/strings.html)

```{r Write some functions}

scrape_html <- function(url) {
  read_html(url) %>% 
  html_node("#my-teams-table") %>% 
  html_nodes(".mod-content") %>% 
  html_nodes("tr") %>% 
  html_text()
}

get_year_data <- function(year) {
  off_url <- off_url %>%  gsub(pattern = "20\\d{2}", replacement = year)
  d_url <- d_url %>%  gsub(pattern = "20\\d{2}", replacement = year)
  misc_url <- misc_url %>%  gsub(pattern = "20\\d{2}", replacement = year)
  
  off_html_data <- scrape_html(off_url)
  off_stats <- get_offensive_stats(off_html_data) 
  
  d_html_data <- scrape_url(d_url)
  d_stats <- get_defensive_stats(d_html_data)
  
  misc_html_data <- scrape_html(misc_url)
  misc_stats <- get_misc_stats(misc_html_data) 
}
```

Before we jump to the next part we'll have a brief interlude to talk about some nifty regular expressions. Square brackets can be thought of as match any of these characters. So [AB] will match the following strings: "A", "B", "AB", "AC", "BC", "ABC". It will not match the string "CDE". \\d will match any digit 0-9 and \\s will match any whitespace character (tab, space, etc.). Each of the regular expressions mentioned will match exactly once. The function str_extract() takes a regular expression and extracts any corresponding strings matching that pattern. So using str_extract() with the pattern "[AB]" and the string "ABC" will return just "A". Using the same on the string "CBC" will return just "B". 

We can use numeric operators as well. Appending an expression with ? equates to match whenever that expression ocurrs zero or one times. "*" means match zero or more times, and "+" means match one or more times. Appending with {x,y} where x and y are numbers, means match any amount between x and y times. Examples can be found in the following paragraph, and additional reading about regular expressions can be found here: https://r4ds.had.co.nz/strings.html

Since team names haven't changed since 2014, and since they are in the same place (albeit in different orders) for all three webpages, we can write a functiion that will take in the html_data for a partcular page and extract the team names. We'll use str_extract() to pass in another regular expression and rerturn any strings that match that pattern. Since we notice that most of the team names are preceded by a one or two digit number, we'll extract any strings that have one or zero digits (\\d?), followed by any capital letter ([A-Z]), followed by one or more lowercase letters ([a-z]+), followed by zero or more spaces (\\s\*), followed by zero or more upperr or lowercase letters ([A-Za-z]\*), followed by a digit. Then we'll pass the resulting string into str_extract() again to discard the numbers we swept up. Finally, we'll use gsub() to get rid of any spaces, and na.omit() to get rid of any rows with NA. Both of these final operations will be useful to us later on. 

```{r Separate Team Names}

extract_team_names <- function(html_data) {
  html_data %>% 
    str_extract("\\d?[A-Z][a-z]+\\s*[A-Za-z]*\\d") %>% 
    str_extract("[A-Z][a-z]+\\s*[A-Za-z]*") %>% 
    gsub(pattern = "\\s", replacement = c("")) %>% 
    na.omit()
}

```

Now that we have our html data, and a way to pull the team names, its time to do the heavy lifting. We'll write three more functions; one function will be for offensive statistics, one for defensive, and one for misc. They will all have similar methodology, but with slight variations due to the dataset. The general idea is that we'll pass in the html data for the page with the corresponding stats, use the extract_team_names() function we wrote and save it for later. Next we'll use str_remove_all to remove all non-numeric values from the data. Once the raw data is obtained, we'll separate 

We'll then create a dataframe with each team being an entity and each statistical category being an attribute. Because there is no clear delimiter in the data, we'll need to treat it as a giant string and create substrings based on the length of the corresponding statistics. We'll then have to use the slice() function to get rid of the rows that have attribute headers instead of statistics. Finally, we'll add the team names back to the statistics dataframe with the mutate() function and then use select to move team name to the front so that the team name is the first attribute in the table.

```{r MORE FUNCTIONS!!!}

get_offensive_stats <- function(html_data) {
  team_names_data <-  extract_team_names(html_data)
  off_stat_data <- html_data %>%
    str_remove_all("^\\d*\\s*[A-Za-z]*\\s?[A-Za-z]*") 

  off_stat_tab <- data.frame(PPG = substr(off_stat_data,1,5),
                              FGM = substr(off_stat_data,6,9),
                              FGA = substr(off_stat_data,10,13),
                              FGP = substr(off_stat_data,14,17),
                             #some teams have fewer chars in this category. 
                             #ex. OKC has 8.4 vs BKN has 10.7 and this is screwing up the remaining stuff
                              TPM = substr(off_stat_data,18,20),
                              TPA = substr(off_stat_data,21,25),
                              TPP = substr(off_stat_data,26,29),
                              FTM = substr(off_stat_data,30,33),
                              FTA = substr(off_stat_data,34,37),
                              FTP = substr(off_stat_data,38,41),
                              PPS = substr(off_stat_data,42,45),
                              AFGP = substr(off_stat_data,46,50)) %>% 
      slice(-1) %>% 
      slice(-11) %>% 
      slice(-21) %>% 
      mutate(Team_Name = team_names_data)
  off_stat_tab <- off_stat_tab %>% 
    select(Team_Name, everything())
  
}


get_defensive_stats <- function(html_data) {
  team_names_data <-  extract_team_names(html_data)
  def_stat_data <- html_data %>% 
    str_remove_all("^\\d*\\s*[A-Za-z]*\\s?[A-Za-z]*")
  
  def_stat_tab <- data.frame(Opp_PPG = substr(def_stat_data,1,5),
                              Opp_FGM = substr(def_stat_data,6,9),
                              Opp_FGA = substr(def_stat_data,10,13),
                              Opp_FGP = substr(def_stat_data,14,17),
                              Opp_TPM = substr(def_stat_data,18,20),
                              Opp_TPA = substr(def_stat_data,21,24),
                              Opp_TPP = substr(def_stat_data,25,28),
                              Opp_FTM = substr(def_stat_data,29,32),
                              Opp_FTA = substr(def_stat_data,33,36),
                              Opp_FTP = substr(def_stat_data,37,40),
                              Opp_PPS = substr(def_stat_data,41,44),
                              Opp_AFGP = substr(def_stat_data,45,49)) %>% 
      slice(-1) %>% 
      slice(-11) %>% 
      slice(-21) %>% 
      mutate(Team_Name = team_names_data)
  def_stat_tab <- def_stat_tab %>% 
    select(Team_Name, everything())
  
}

get_misc_stats <- function(html_data) {
  team_names_data <-  extract_team_names(html_data)
  misc_stat_data <- html_data %>%
    str_remove_all("^\\d*\\s*[A-Za-z]*\\s?[A-Za-z]*")
   misc_stat_tab <- data.frame(AST = substr(misc_stat_data,1,4),
                              Opp_AST = substr(misc_stat_data,5,8),
                              STL = substr(misc_stat_data,9,11),
                              Opp_STL = substr(misc_stat_data,12,14),
                              BLK = substr(misc_stat_data,15,17),
                              Opp_BLK = substr(misc_stat_data,18,21),
                              TRN = substr(misc_stat_data,22,25),
                              Opp_TRN = substr(misc_stat_data,26,28),
                              DIFF = substr(misc_stat_data,29,32),
                              ATO = substr(misc_stat_data,33,36),
                              TECH = substr(misc_stat_data,37,39)) %>%
      slice(-1:-2) %>%
      slice(-11:-12) %>%
      slice(-21:-22) %>%
      mutate(Team_Name = team_names_data) 
  misc_stat_tab <- misc_stat_tab %>%
    select(Team_Name, everything())
}




```


```{r Put it all together}

off_url <- "http://www.espn.com/nba/statistics/team/_/stat/offense-per-game/year/2015/seasontype/2"

d_url <- "http://www.espn.com/nba/statistics/team/_/stat/defense-per-game/year/2015/seasontype/2"

misc_url <- "http://www.espn.com/nba/statistics/team/_/stat/miscellaneous-per-game/year/2015/seasontype/2"


get_year_data <- function(year) {
  off_url <- off_url %>%  gsub(pattern = "20\\d{2}", replacement = year)
  d_url <- d_url %>%  gsub(pattern = "20\\d{2}", replacement = year)
  misc_url <- misc_url %>%  gsub(pattern = "20\\d{2}", replacement = year)
  
  off_html_data <- read_html(off_url) %>% 
  html_node("#my-teams-table") %>% 
  html_nodes(".mod-content") %>% 
  html_nodes("tr") %>% 
  html_text()
  off_stats <- get_offensive_stats(off_html_data)
  
  d_html_data <- read_html(d_url) %>% 
  html_node("#my-teams-table") %>% 
  html_nodes(".mod-content") %>% 
  html_nodes("tr") %>% 
  html_text()
  d_stats <- get_defensive_stats(d_html_data)
  
  misc_html_data <- read_html(misc_url) %>% 
  html_node("#my-teams-table") %>% 
  html_nodes(".mod-content") %>% 
  html_nodes("tr") %>% 
  html_text()
  misc_stats <- get_misc_stats(misc_html_data)
  
  
  stats_tab <- full_join(off_stats, d_stats, misc_stats, by = "Team_Name")
  view(stats_tab)
  
}

html_data <- get_year_data(2017)
html_data

```


```{r extras}

# #extract team names 
# team_names <- teams_html_tab %>% 
#   str_extract("title=.*</a>") %>% 
#   str_extract("[A-Z](\\w|\\s)*")
# 
# team_shortnames <- teams_html_tab %>% 
#   str_extract("title=.*</a>") %>% 
#   str_extract("[A-Z]{3}")
# 
# team_pages <- teams_html_tab %>% 
#   str_extract("href=.*\\.html") %>% 
#   str_extract("/.*\\.html") %>% 
#   str_extract("\\w.*")


  
team_pages <- paste0(url, "teams/", team_shortnames, "/")
#dates <- paste0(2014:2019, ".html")

teams_tab <- data_frame(Team_Name = team_names, Team_Code = team_shortnames, Team_Page = team_pages, FGA = "", Opp_FGA = "", AST = "", STL = "", Opp_STL = "", BLK = "", Opp_BLK = "", TOV_percent = "", Opp_TOV_percent = "", PTS = "", OPTS = "", Margin_of_victory = "", ORTG = "", DRTG = "", Pace = "", free_throw_attempt_rate = "", opp_free_throw_attempt_rate = "", total_dunks = "", usage_spread = "", star_power = "", age_of_stars = "")


get_year_data <- function(team, year){
  
  curr_team <- teams_tab %>% 
     filter(Team_Code == team)
  
  url <- paste0(curr_team$Team_Page, year, ".html")
  
  
  read_html(url) %>% 
    html_node(".team_and_opponent") %>% 
    html_table()
   # html_nodes("[scope]")

   
 }
 
get_year_data("MIL", 2019)
#   do_stuff()
# }

```




```{r Get Table}


get_season_stats <- function(url){
  stats_tab <- read_html(url) %>%
  html_node(".stats_table") %>%
  html_table() %>% 
  as_data_frame()
  
  stats_tab
}

season2019 <- get_season_stats("https://www.basketball-reference.com/leagues/NBA_2019_per_game.html")
season2019

```